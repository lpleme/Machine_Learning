{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bikes.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOsAMaA9h1kmccm7KTg57Vw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lpleme/Machine_Learning/blob/main/bikes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOkVPMf4FC8r"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "from keras import models  \n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "SHUFFLE_BUFFER = 500\n",
        "#BATCH_SIZE = 2\n",
        "#BATCH_SIZE = 5 # Increased the amount of nodes, then we increased the total number of epochs which show how many times it runs through the model.\n",
        "#BATCH_SIZE = 2 # epoch 25 result = 57, result = 42.9661\n",
        "#BATCH_SIZE = 2 # added season and weathersit not hot_encoded\n",
        "#BATCH_SIZE = 2 # hot encoded season and weather sit\n",
        "#BATCH_SIZE = 2\n",
        "\n",
        "#This is the batch size we'll be using\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "bikes = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/bikes.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibK2Yi-BFHIw"
      },
      "source": [
        "#Splits the date into month, day, and year\n",
        "bikes[\"month\"] = bikes.dteday.str.split('/').str[0]\n",
        "bikes[\"day\"] = bikes.dteday.str.split('/').str[1]\n",
        "bikes[\"year\"] = bikes.dteday.str.split('/').str[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "wiVM2gfqFJem",
        "outputId": "b86b3f68-5c2e-4e1a-8f6b-22792ece5433"
      },
      "source": [
        "#Makes a rent column that adds the casual and registered users\n",
        "bikes['rent'] = bikes['casual'] + bikes['registered']\n",
        "bikes\n",
        "\n",
        "bikes1 = bikes\n",
        "\n",
        "bikes1 = pd.get_dummies(bikes1, columns = ['season', 'weathersit'])\n",
        "#bikes1 = pd.get_dummies(bikes1, columns = ['season', 'weathersit','month','year','day'])\n",
        "bikes1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dteday</th>\n",
              "      <th>hr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>temp_c</th>\n",
              "      <th>feels_like_c</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>year</th>\n",
              "      <th>rent</th>\n",
              "      <th>season_1</th>\n",
              "      <th>season_2</th>\n",
              "      <th>season_3</th>\n",
              "      <th>season_4</th>\n",
              "      <th>weathersit_1</th>\n",
              "      <th>weathersit_2</th>\n",
              "      <th>weathersit_3</th>\n",
              "      <th>weathersit_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/1/11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0</td>\n",
              "      <td>3.28</td>\n",
              "      <td>3.0014</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/1/11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0</td>\n",
              "      <td>2.34</td>\n",
              "      <td>1.9982</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/1/11</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0</td>\n",
              "      <td>2.34</td>\n",
              "      <td>1.9982</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/1/11</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0</td>\n",
              "      <td>3.28</td>\n",
              "      <td>3.0014</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1/1/11</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0</td>\n",
              "      <td>3.28</td>\n",
              "      <td>3.0014</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   dteday  hr  holiday  ...  weathersit_2  weathersit_3  weathersit_4\n",
              "0  1/1/11   0        0  ...             0             0             0\n",
              "1  1/1/11   1        0  ...             0             0             0\n",
              "2  1/1/11   2        0  ...             0             0             0\n",
              "3  1/1/11   3        0  ...             0             0             0\n",
              "4  1/1/11   4        0  ...             0             0             0\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-lOAp71FLdV"
      },
      "source": [
        "#Sets the target\n",
        "target = bikes['rent']\n",
        "target = bikes1['rent']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "OLZt0rG6FNdj",
        "outputId": "cd51c114-222f-44f5-83b1-26bb563f90c8"
      },
      "source": [
        "numeric_feature_names = ['hr', 'holiday', 'workingday',  'hum', 'windspeed', 'temp_c', 'feels_like_c', 'season', 'weathersit']\n",
        "numeric_features = bikes[numeric_feature_names]\n",
        "numeric_features.head()\n",
        "\n",
        "\n",
        "#We will use these numeric features in our model. This turns out values into something that the model can read\n",
        "numeric_feature_names1 = ['hr', 'holiday', 'workingday',  'hum', 'windspeed', 'temp_c', 'feels_like_c', 'season_1', 'season_2', 'season_3', 'season_4', 'weathersit_1', 'weathersit_2', 'weathersit_3', 'weathersit_4']\n",
        "#numeric_feature_names1 = ['hr', 'holiday', 'workingday',  'hum', 'windspeed', 'temp_c', 'feels_like_c', 'season_1', 'season_2', 'season_3', 'season_4', 'weathersit_1', 'weathersit_2', 'weathersit_3', 'weathersit_4', 'month', 'day', 'year'] # I tried adding month, day, year but it said that it failed to convert those to numpy\n",
        "numeric_features1 = bikes1[numeric_feature_names1]\n",
        "numeric_features1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>temp_c</th>\n",
              "      <th>feels_like_c</th>\n",
              "      <th>season_1</th>\n",
              "      <th>season_2</th>\n",
              "      <th>season_3</th>\n",
              "      <th>season_4</th>\n",
              "      <th>weathersit_1</th>\n",
              "      <th>weathersit_2</th>\n",
              "      <th>weathersit_3</th>\n",
              "      <th>weathersit_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0</td>\n",
              "      <td>3.28</td>\n",
              "      <td>3.0014</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0</td>\n",
              "      <td>2.34</td>\n",
              "      <td>1.9982</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0</td>\n",
              "      <td>2.34</td>\n",
              "      <td>1.9982</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0</td>\n",
              "      <td>3.28</td>\n",
              "      <td>3.0014</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0</td>\n",
              "      <td>3.28</td>\n",
              "      <td>3.0014</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   hr  holiday  workingday  ...  weathersit_2  weathersit_3  weathersit_4\n",
              "0   0        0           0  ...             0             0             0\n",
              "1   1        0           0  ...             0             0             0\n",
              "2   2        0           0  ...             0             0             0\n",
              "3   3        0           0  ...             0             0             0\n",
              "4   4        0           0  ...             0             0             0\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nncDDOwWFPGm",
        "outputId": "3b935000-bd9a-4156-898b-4f7cbd3d1928"
      },
      "source": [
        "#Converting our numeric features readable by tensor\n",
        "#tf.convert_to_tensor(numeric_features)\n",
        "tf.convert_to_tensor(numeric_features1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(16637, 15), dtype=float64, numpy=\n",
              "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "       [ 2.,  0.,  0., ...,  0.,  0.,  0.],\n",
              "       ...,\n",
              "       [21.,  0.,  1., ...,  0.,  0.,  0.],\n",
              "       [22.,  0.,  1., ...,  0.,  0.,  0.],\n",
              "       [23.,  0.,  1., ...,  1.,  0.,  0.]])>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXy3Tb34FQ1X"
      },
      "source": [
        "#normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "#normalizer.adapt(numeric_features)\n",
        "\n",
        "#Normalizes our values so we don't have major outliers while running the model\n",
        "normalizer1 = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer1.adapt(numeric_features1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXnw1RIQFTVH",
        "outputId": "8e73659f-ffe2-459d-c3e5-00d2c028740d"
      },
      "source": [
        "#normalizer(numeric_features.iloc[:3])\n",
        "# shows what is going on\n",
        "\n",
        "\n",
        "normalizer1(numeric_features1.iloc[:3])\n",
        "# shows what is going on"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 15), dtype=float32, numpy=\n",
              "array([[-1.6702179 , -0.17180604, -1.4725312 ,  0.9587179 , -1.5609912 ,\n",
              "        -1.3762757 , -1.1349833 ,  1.7832977 , -0.60047174, -0.60853565,\n",
              "        -0.53962135,  0.7083815 , -0.5817692 , -0.2970507 , -0.01342958],\n",
              "       [-1.5255835 , -0.17180604, -1.4725312 ,  0.90696377, -1.5609912 ,\n",
              "        -1.4802456 , -1.2235863 ,  1.7832977 , -0.60047174, -0.60853565,\n",
              "        -0.53962135,  0.7083815 , -0.5817692 , -0.2970507 , -0.01342958],\n",
              "       [-1.3809493 , -0.17180604, -1.4725312 ,  0.90696377, -1.5609912 ,\n",
              "        -1.4802456 , -1.2235863 ,  1.7832977 , -0.60047174, -0.60853565,\n",
              "        -0.53962135,  0.7083815 , -0.5817692 , -0.2970507 , -0.01342958]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9VcEZ6XFVSs"
      },
      "source": [
        "#This it the function that creates the model and its parameters. \n",
        "# KEEP THIS TO LEARN FROM THIS #2\n",
        "def get_basic_model():\n",
        "  model = tf.keras.Sequential([\n",
        "    normalizer1,\n",
        "    tf.keras.layers.Dense(30, activation='relu'), #the more perceptrons/nodes, the more of the abstract features () you can take. Just like from the interactive video, I'm adding 10 neurons to train off. 15 here instead.\n",
        "    tf.keras.layers.Dense(30, activation='relu'), #this is the other hidden layer, combines the inputs from the previous layer\n",
        "    tf.keras.layers.Dense(30, activation='relu'),\n",
        "    tf.keras.layers.Dense(30, activation='relu'),\n",
        "    tf.keras.layers.Dense(30, activation='relu'),\n",
        "    tf.keras.layers.Dense(30, activation='relu'), # I changed the dense thing from 10 to 15 to account for the 15 features I'm implementing. I then changed it from 15 to 20 and got a result of 32.3014\n",
        "    #tf.keras.layers.Dense(20, activation='relu'), # I tried adding another hidden layer but I ended up only getting 33.5268\n",
        "    tf.keras.layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "                #(this is for a classification )loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                loss = tf.keras.losses.MeanAbsoluteError(), # this one is for regressions\n",
        "                metrics = ['mean_absolute_error'])\n",
        "                # metrics = ['accuracy'] # This one for classification\n",
        "\n",
        "\n",
        "  # accuracy is more for classification\n",
        "  # for regression we would want to switch to mean^2; r^2\n",
        "  # I can add more tf.keras.layers.Dense intomy model\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpWyAqFNFbly",
        "outputId": "58b6df32-22aa-4294-e194-2e99267f1c56"
      },
      "source": [
        "#2\n",
        "#This runs the model and trains the neural network\n",
        "model = get_basic_model()\n",
        "model.fit(numeric_features1, target, epochs=140, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/140\n",
            "520/520 [==============================] - 2s 2ms/step - loss: 112.3184 - mean_absolute_error: 112.3184\n",
            "Epoch 2/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 86.3781 - mean_absolute_error: 86.3781\n",
            "Epoch 3/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 74.1865 - mean_absolute_error: 74.1865\n",
            "Epoch 4/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 70.3007 - mean_absolute_error: 70.3007\n",
            "Epoch 5/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 68.0572 - mean_absolute_error: 68.0572\n",
            "Epoch 6/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 66.3615 - mean_absolute_error: 66.3615\n",
            "Epoch 7/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 64.3472 - mean_absolute_error: 64.3472\n",
            "Epoch 8/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 62.0678 - mean_absolute_error: 62.0678\n",
            "Epoch 9/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 59.3927 - mean_absolute_error: 59.3927\n",
            "Epoch 10/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 57.3822 - mean_absolute_error: 57.3822\n",
            "Epoch 11/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 55.3810 - mean_absolute_error: 55.3810\n",
            "Epoch 12/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 53.4475 - mean_absolute_error: 53.4475\n",
            "Epoch 13/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 52.3687 - mean_absolute_error: 52.3687\n",
            "Epoch 14/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 51.9267 - mean_absolute_error: 51.9267\n",
            "Epoch 15/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 51.0116 - mean_absolute_error: 51.0116\n",
            "Epoch 16/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 50.6191 - mean_absolute_error: 50.6191\n",
            "Epoch 17/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 50.5517 - mean_absolute_error: 50.5517\n",
            "Epoch 18/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 50.1601 - mean_absolute_error: 50.1601\n",
            "Epoch 19/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 49.4956 - mean_absolute_error: 49.4956\n",
            "Epoch 20/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 49.2782 - mean_absolute_error: 49.2782\n",
            "Epoch 21/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 49.0595 - mean_absolute_error: 49.0595\n",
            "Epoch 22/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 49.1910 - mean_absolute_error: 49.1910\n",
            "Epoch 23/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 49.0085 - mean_absolute_error: 49.0085\n",
            "Epoch 24/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 48.7008 - mean_absolute_error: 48.7008\n",
            "Epoch 25/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 48.4439 - mean_absolute_error: 48.4439\n",
            "Epoch 26/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 48.5844 - mean_absolute_error: 48.5844\n",
            "Epoch 27/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 48.4197 - mean_absolute_error: 48.4197\n",
            "Epoch 28/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 48.1260 - mean_absolute_error: 48.1260\n",
            "Epoch 29/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 48.1485 - mean_absolute_error: 48.1485\n",
            "Epoch 30/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 47.9861 - mean_absolute_error: 47.9861\n",
            "Epoch 31/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 48.1307 - mean_absolute_error: 48.1307\n",
            "Epoch 32/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 47.6132 - mean_absolute_error: 47.6132\n",
            "Epoch 33/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 47.4729 - mean_absolute_error: 47.4729\n",
            "Epoch 34/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 47.6502 - mean_absolute_error: 47.6502\n",
            "Epoch 35/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 47.2719 - mean_absolute_error: 47.2719\n",
            "Epoch 36/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 47.2551 - mean_absolute_error: 47.2551\n",
            "Epoch 37/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 46.9833 - mean_absolute_error: 46.9833\n",
            "Epoch 38/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 47.1373 - mean_absolute_error: 47.1373\n",
            "Epoch 39/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 46.9653 - mean_absolute_error: 46.9653\n",
            "Epoch 40/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 46.7923 - mean_absolute_error: 46.7923\n",
            "Epoch 41/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 46.5333 - mean_absolute_error: 46.5333\n",
            "Epoch 42/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 46.7438 - mean_absolute_error: 46.7438\n",
            "Epoch 43/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 46.8523 - mean_absolute_error: 46.8523\n",
            "Epoch 44/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 46.6469 - mean_absolute_error: 46.6469\n",
            "Epoch 45/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 46.5781 - mean_absolute_error: 46.5781\n",
            "Epoch 46/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 46.7613 - mean_absolute_error: 46.7613\n",
            "Epoch 47/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 46.2840 - mean_absolute_error: 46.2840\n",
            "Epoch 48/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 46.1741 - mean_absolute_error: 46.1741\n",
            "Epoch 49/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 45.9973 - mean_absolute_error: 45.9973\n",
            "Epoch 50/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 46.1555 - mean_absolute_error: 46.1555\n",
            "Epoch 51/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 46.0701 - mean_absolute_error: 46.0701\n",
            "Epoch 52/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 45.9759 - mean_absolute_error: 45.9759\n",
            "Epoch 53/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 45.8722 - mean_absolute_error: 45.8722\n",
            "Epoch 54/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 45.5393 - mean_absolute_error: 45.5393\n",
            "Epoch 55/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 45.6170 - mean_absolute_error: 45.6170\n",
            "Epoch 56/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 46.0313 - mean_absolute_error: 46.0313\n",
            "Epoch 57/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 45.6056 - mean_absolute_error: 45.6056\n",
            "Epoch 58/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 45.7388 - mean_absolute_error: 45.7388\n",
            "Epoch 59/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 45.3596 - mean_absolute_error: 45.3596\n",
            "Epoch 60/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 45.4350 - mean_absolute_error: 45.4350\n",
            "Epoch 61/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 45.2287 - mean_absolute_error: 45.2287\n",
            "Epoch 62/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 45.3996 - mean_absolute_error: 45.3996\n",
            "Epoch 63/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 45.3222 - mean_absolute_error: 45.3222\n",
            "Epoch 64/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 45.1930 - mean_absolute_error: 45.1930\n",
            "Epoch 65/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 45.3842 - mean_absolute_error: 45.3842\n",
            "Epoch 66/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 45.1489 - mean_absolute_error: 45.1489\n",
            "Epoch 67/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 45.3954 - mean_absolute_error: 45.3954\n",
            "Epoch 68/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 45.2889 - mean_absolute_error: 45.2889\n",
            "Epoch 69/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 45.1988 - mean_absolute_error: 45.1988\n",
            "Epoch 70/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 44.7284 - mean_absolute_error: 44.7284\n",
            "Epoch 71/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 45.3902 - mean_absolute_error: 45.3902\n",
            "Epoch 72/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 44.6781 - mean_absolute_error: 44.6781\n",
            "Epoch 73/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 44.8181 - mean_absolute_error: 44.8181\n",
            "Epoch 74/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 44.7823 - mean_absolute_error: 44.7823\n",
            "Epoch 75/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 44.6161 - mean_absolute_error: 44.6161\n",
            "Epoch 76/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 44.9114 - mean_absolute_error: 44.9114\n",
            "Epoch 77/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 44.5778 - mean_absolute_error: 44.5778\n",
            "Epoch 78/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 44.3558 - mean_absolute_error: 44.3558\n",
            "Epoch 79/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 44.7346 - mean_absolute_error: 44.7346\n",
            "Epoch 80/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 44.3376 - mean_absolute_error: 44.3376\n",
            "Epoch 81/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 44.5632 - mean_absolute_error: 44.5632\n",
            "Epoch 82/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 44.3175 - mean_absolute_error: 44.3175\n",
            "Epoch 83/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 44.6543 - mean_absolute_error: 44.6543\n",
            "Epoch 84/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 44.5369 - mean_absolute_error: 44.5369\n",
            "Epoch 85/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 44.3903 - mean_absolute_error: 44.3903\n",
            "Epoch 86/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 44.2427 - mean_absolute_error: 44.2427\n",
            "Epoch 87/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 44.3828 - mean_absolute_error: 44.3828\n",
            "Epoch 88/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 44.2971 - mean_absolute_error: 44.2971\n",
            "Epoch 89/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 44.2052 - mean_absolute_error: 44.2052\n",
            "Epoch 90/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 44.2044 - mean_absolute_error: 44.2044\n",
            "Epoch 91/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.8030 - mean_absolute_error: 43.8030\n",
            "Epoch 92/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 44.2415 - mean_absolute_error: 44.2415\n",
            "Epoch 93/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.9978 - mean_absolute_error: 43.9978\n",
            "Epoch 94/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.9434 - mean_absolute_error: 43.9434\n",
            "Epoch 95/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 44.1697 - mean_absolute_error: 44.1697\n",
            "Epoch 96/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 44.3142 - mean_absolute_error: 44.3142\n",
            "Epoch 97/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 44.0257 - mean_absolute_error: 44.0257\n",
            "Epoch 98/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.6816 - mean_absolute_error: 43.6816\n",
            "Epoch 99/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.7854 - mean_absolute_error: 43.7854\n",
            "Epoch 100/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.8044 - mean_absolute_error: 43.8044\n",
            "Epoch 101/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.8932 - mean_absolute_error: 43.8932\n",
            "Epoch 102/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.6940 - mean_absolute_error: 43.6940\n",
            "Epoch 103/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.7596 - mean_absolute_error: 43.7596\n",
            "Epoch 104/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.8072 - mean_absolute_error: 43.8072\n",
            "Epoch 105/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.5728 - mean_absolute_error: 43.5728\n",
            "Epoch 106/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.6636 - mean_absolute_error: 43.6636\n",
            "Epoch 107/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.3302 - mean_absolute_error: 43.3302\n",
            "Epoch 108/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.6065 - mean_absolute_error: 43.6065\n",
            "Epoch 109/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.4931 - mean_absolute_error: 43.4931\n",
            "Epoch 110/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.1562 - mean_absolute_error: 43.1562\n",
            "Epoch 111/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.6343 - mean_absolute_error: 43.6343\n",
            "Epoch 112/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.4353 - mean_absolute_error: 43.4353\n",
            "Epoch 113/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.3291 - mean_absolute_error: 43.3291\n",
            "Epoch 114/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.5641 - mean_absolute_error: 43.5641\n",
            "Epoch 115/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.2459 - mean_absolute_error: 43.2459\n",
            "Epoch 116/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.3613 - mean_absolute_error: 43.3613\n",
            "Epoch 117/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.3100 - mean_absolute_error: 43.3100\n",
            "Epoch 118/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.2043 - mean_absolute_error: 43.2043\n",
            "Epoch 119/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.2219 - mean_absolute_error: 43.2219\n",
            "Epoch 120/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.2204 - mean_absolute_error: 43.2204\n",
            "Epoch 121/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.0915 - mean_absolute_error: 43.0915\n",
            "Epoch 122/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.3001 - mean_absolute_error: 43.3001\n",
            "Epoch 123/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.1608 - mean_absolute_error: 43.1608\n",
            "Epoch 124/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 42.9247 - mean_absolute_error: 42.9247\n",
            "Epoch 125/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.1892 - mean_absolute_error: 43.1892\n",
            "Epoch 126/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 42.9461 - mean_absolute_error: 42.9461\n",
            "Epoch 127/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 42.9042 - mean_absolute_error: 42.9042\n",
            "Epoch 128/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 43.0976 - mean_absolute_error: 43.0976\n",
            "Epoch 129/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 42.7516 - mean_absolute_error: 42.7516\n",
            "Epoch 130/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 42.7508 - mean_absolute_error: 42.7508\n",
            "Epoch 131/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 42.8853 - mean_absolute_error: 42.8853\n",
            "Epoch 132/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 42.6714 - mean_absolute_error: 42.6714\n",
            "Epoch 133/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 42.3856 - mean_absolute_error: 42.3856\n",
            "Epoch 134/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 42.7568 - mean_absolute_error: 42.7568\n",
            "Epoch 135/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 42.7818 - mean_absolute_error: 42.7818\n",
            "Epoch 136/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 42.6587 - mean_absolute_error: 42.6587\n",
            "Epoch 137/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 42.5802 - mean_absolute_error: 42.5802\n",
            "Epoch 138/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 42.5483 - mean_absolute_error: 42.5483\n",
            "Epoch 139/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 42.3729 - mean_absolute_error: 42.3729\n",
            "Epoch 140/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 42.5503 - mean_absolute_error: 42.5503\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0018b716d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VO4VIjENGjQb",
        "outputId": "b4cb5ebc-e316-4866-c01e-79107fc0f2e2"
      },
      "source": [
        "#2\n",
        "numeric_dataset = tf.data.Dataset.from_tensor_slices((numeric_features1, target))\n",
        "\n",
        "for row in numeric_dataset.take(3):\n",
        "  print(row)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(15,), dtype=float64, numpy=\n",
            "array([0.    , 0.    , 0.    , 0.81  , 0.    , 3.28  , 3.0014, 1.    ,\n",
            "       0.    , 0.    , 0.    , 1.    , 0.    , 0.    , 0.    ])>, <tf.Tensor: shape=(), dtype=int64, numpy=16>)\n",
            "(<tf.Tensor: shape=(15,), dtype=float64, numpy=\n",
            "array([1.    , 0.    , 0.    , 0.8   , 0.    , 2.34  , 1.9982, 1.    ,\n",
            "       0.    , 0.    , 0.    , 1.    , 0.    , 0.    , 0.    ])>, <tf.Tensor: shape=(), dtype=int64, numpy=40>)\n",
            "(<tf.Tensor: shape=(15,), dtype=float64, numpy=\n",
            "array([2.    , 0.    , 0.    , 0.8   , 0.    , 2.34  , 1.9982, 1.    ,\n",
            "       0.    , 0.    , 0.    , 1.    , 0.    , 0.    , 0.    ])>, <tf.Tensor: shape=(), dtype=int64, numpy=32>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs8yKpFEFf8p",
        "outputId": "bb46141b-4ff1-4d67-b2dd-5deaf7128ca3"
      },
      "source": [
        "#This will shuffel our numeric dataset and run the model again\n",
        "numeric_batches = numeric_dataset.shuffle(1000).batch(BATCH_SIZE)\n",
        "\n",
        "model = get_basic_model()\n",
        "model.fit(numeric_batches, epochs=140)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 100.1323 - mean_absolute_error: 100.1323\n",
            "Epoch 2/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 85.4510 - mean_absolute_error: 85.4510\n",
            "Epoch 3/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 72.1141 - mean_absolute_error: 72.1141\n",
            "Epoch 4/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 64.1916 - mean_absolute_error: 64.1916\n",
            "Epoch 5/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 60.5782 - mean_absolute_error: 60.5782\n",
            "Epoch 6/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 57.9402 - mean_absolute_error: 57.9402\n",
            "Epoch 7/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 55.1550 - mean_absolute_error: 55.1550\n",
            "Epoch 8/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 52.0237 - mean_absolute_error: 52.0237\n",
            "Epoch 9/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 47.8446 - mean_absolute_error: 47.8446\n",
            "Epoch 10/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 45.0052 - mean_absolute_error: 45.0052\n",
            "Epoch 11/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 41.5024 - mean_absolute_error: 41.5024\n",
            "Epoch 12/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 39.4469 - mean_absolute_error: 39.4469\n",
            "Epoch 13/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 37.5513 - mean_absolute_error: 37.5513\n",
            "Epoch 14/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 36.6808 - mean_absolute_error: 36.6808\n",
            "Epoch 15/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 36.3812 - mean_absolute_error: 36.3812\n",
            "Epoch 16/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 35.1898 - mean_absolute_error: 35.1898\n",
            "Epoch 17/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 34.9844 - mean_absolute_error: 34.9844\n",
            "Epoch 18/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 34.4609 - mean_absolute_error: 34.4609\n",
            "Epoch 19/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 34.0873 - mean_absolute_error: 34.0873\n",
            "Epoch 20/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 34.1709 - mean_absolute_error: 34.1709\n",
            "Epoch 21/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 33.4126 - mean_absolute_error: 33.4126\n",
            "Epoch 22/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 33.5438 - mean_absolute_error: 33.5438\n",
            "Epoch 23/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 33.2622 - mean_absolute_error: 33.2622\n",
            "Epoch 24/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 32.8446 - mean_absolute_error: 32.8446\n",
            "Epoch 25/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 32.8717 - mean_absolute_error: 32.8717\n",
            "Epoch 26/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 32.9366 - mean_absolute_error: 32.9366\n",
            "Epoch 27/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 32.2123 - mean_absolute_error: 32.2123\n",
            "Epoch 28/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 32.7755 - mean_absolute_error: 32.7755\n",
            "Epoch 29/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 32.4494 - mean_absolute_error: 32.4494\n",
            "Epoch 30/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 32.2425 - mean_absolute_error: 32.2425\n",
            "Epoch 31/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 31.9410 - mean_absolute_error: 31.9410\n",
            "Epoch 32/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 31.9379 - mean_absolute_error: 31.9379\n",
            "Epoch 33/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 32.2579 - mean_absolute_error: 32.2579\n",
            "Epoch 34/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 32.3891 - mean_absolute_error: 32.3891\n",
            "Epoch 35/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 32.2768 - mean_absolute_error: 32.2768\n",
            "Epoch 36/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 31.6168 - mean_absolute_error: 31.6168\n",
            "Epoch 37/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 31.5924 - mean_absolute_error: 31.5924\n",
            "Epoch 38/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 31.6538 - mean_absolute_error: 31.6538\n",
            "Epoch 39/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 31.3848 - mean_absolute_error: 31.3848\n",
            "Epoch 40/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 31.4151 - mean_absolute_error: 31.4151\n",
            "Epoch 41/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 31.8773 - mean_absolute_error: 31.8773\n",
            "Epoch 42/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.9635 - mean_absolute_error: 30.9635\n",
            "Epoch 43/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 31.1640 - mean_absolute_error: 31.1640\n",
            "Epoch 44/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 31.1483 - mean_absolute_error: 31.1483\n",
            "Epoch 45/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 31.3800 - mean_absolute_error: 31.3800\n",
            "Epoch 46/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 31.2210 - mean_absolute_error: 31.2210\n",
            "Epoch 47/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 31.2240 - mean_absolute_error: 31.2240\n",
            "Epoch 48/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 31.4576 - mean_absolute_error: 31.4576\n",
            "Epoch 49/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 31.2553 - mean_absolute_error: 31.2553\n",
            "Epoch 50/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.8101 - mean_absolute_error: 30.8101\n",
            "Epoch 51/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 31.2999 - mean_absolute_error: 31.2999\n",
            "Epoch 52/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.4939 - mean_absolute_error: 30.4939\n",
            "Epoch 53/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.7737 - mean_absolute_error: 30.7737\n",
            "Epoch 54/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 31.3549 - mean_absolute_error: 31.3549\n",
            "Epoch 55/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 31.5194 - mean_absolute_error: 31.5194\n",
            "Epoch 56/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.9509 - mean_absolute_error: 30.9509\n",
            "Epoch 57/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.7484 - mean_absolute_error: 30.7484\n",
            "Epoch 58/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 31.0080 - mean_absolute_error: 31.0080\n",
            "Epoch 59/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.8411 - mean_absolute_error: 30.8411\n",
            "Epoch 60/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.4193 - mean_absolute_error: 30.4193\n",
            "Epoch 61/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.4674 - mean_absolute_error: 30.4674\n",
            "Epoch 62/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.5578 - mean_absolute_error: 30.5578\n",
            "Epoch 63/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.7795 - mean_absolute_error: 30.7795\n",
            "Epoch 64/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.2634 - mean_absolute_error: 30.2634\n",
            "Epoch 65/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.2642 - mean_absolute_error: 30.2642\n",
            "Epoch 66/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.4107 - mean_absolute_error: 30.4107\n",
            "Epoch 67/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.1902 - mean_absolute_error: 30.1902\n",
            "Epoch 68/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.5838 - mean_absolute_error: 30.5838\n",
            "Epoch 69/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.2193 - mean_absolute_error: 30.2193\n",
            "Epoch 70/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.3893 - mean_absolute_error: 30.3893\n",
            "Epoch 71/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.3833 - mean_absolute_error: 30.3833\n",
            "Epoch 72/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.2053 - mean_absolute_error: 30.2053\n",
            "Epoch 73/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.5287 - mean_absolute_error: 30.5287\n",
            "Epoch 74/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.2401 - mean_absolute_error: 30.2401\n",
            "Epoch 75/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.0461 - mean_absolute_error: 30.0461\n",
            "Epoch 76/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.2351 - mean_absolute_error: 30.2351\n",
            "Epoch 77/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.5837 - mean_absolute_error: 30.5837\n",
            "Epoch 78/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.5479 - mean_absolute_error: 30.5479\n",
            "Epoch 79/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.1632 - mean_absolute_error: 30.1632\n",
            "Epoch 80/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.2485 - mean_absolute_error: 30.2485\n",
            "Epoch 81/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.2320 - mean_absolute_error: 30.2320\n",
            "Epoch 82/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.0815 - mean_absolute_error: 30.0815\n",
            "Epoch 83/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.3438 - mean_absolute_error: 30.3438\n",
            "Epoch 84/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.3247 - mean_absolute_error: 30.3247\n",
            "Epoch 85/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.1965 - mean_absolute_error: 30.1965\n",
            "Epoch 86/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.2158 - mean_absolute_error: 30.2158\n",
            "Epoch 87/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.0925 - mean_absolute_error: 30.0925\n",
            "Epoch 88/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.9109 - mean_absolute_error: 29.9109\n",
            "Epoch 89/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.7711 - mean_absolute_error: 29.7711\n",
            "Epoch 90/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.0182 - mean_absolute_error: 30.0182\n",
            "Epoch 91/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.7720 - mean_absolute_error: 29.7720\n",
            "Epoch 92/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.2724 - mean_absolute_error: 30.2724\n",
            "Epoch 93/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.8268 - mean_absolute_error: 29.8268\n",
            "Epoch 94/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.1846 - mean_absolute_error: 30.1846\n",
            "Epoch 95/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.2830 - mean_absolute_error: 30.2830\n",
            "Epoch 96/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.0253 - mean_absolute_error: 30.0253\n",
            "Epoch 97/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.6512 - mean_absolute_error: 29.6512\n",
            "Epoch 98/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.7776 - mean_absolute_error: 29.7776\n",
            "Epoch 99/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.2069 - mean_absolute_error: 30.2069\n",
            "Epoch 100/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 30.1993 - mean_absolute_error: 30.1993\n",
            "Epoch 101/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.7241 - mean_absolute_error: 29.7241\n",
            "Epoch 102/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.9929 - mean_absolute_error: 29.9929\n",
            "Epoch 103/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.6985 - mean_absolute_error: 29.6985\n",
            "Epoch 104/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.7595 - mean_absolute_error: 29.7595\n",
            "Epoch 105/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.8697 - mean_absolute_error: 29.8697\n",
            "Epoch 106/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.4294 - mean_absolute_error: 29.4294\n",
            "Epoch 107/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.6457 - mean_absolute_error: 29.6457\n",
            "Epoch 108/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.8664 - mean_absolute_error: 29.8664\n",
            "Epoch 109/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.2214 - mean_absolute_error: 29.2214\n",
            "Epoch 110/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.6701 - mean_absolute_error: 29.6701\n",
            "Epoch 111/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.8618 - mean_absolute_error: 29.8618\n",
            "Epoch 112/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.5237 - mean_absolute_error: 29.5237\n",
            "Epoch 113/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.0403 - mean_absolute_error: 29.0403\n",
            "Epoch 114/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.4211 - mean_absolute_error: 29.4211\n",
            "Epoch 115/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.2543 - mean_absolute_error: 29.2543\n",
            "Epoch 116/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.0261 - mean_absolute_error: 29.0261\n",
            "Epoch 117/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.1517 - mean_absolute_error: 29.1517\n",
            "Epoch 118/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 28.9524 - mean_absolute_error: 28.9524\n",
            "Epoch 119/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.1395 - mean_absolute_error: 29.1395\n",
            "Epoch 120/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.0665 - mean_absolute_error: 29.0665\n",
            "Epoch 121/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.4762 - mean_absolute_error: 29.4762\n",
            "Epoch 122/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.8302 - mean_absolute_error: 29.8302\n",
            "Epoch 123/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.3684 - mean_absolute_error: 29.3684\n",
            "Epoch 124/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.6698 - mean_absolute_error: 29.6698\n",
            "Epoch 125/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.7911 - mean_absolute_error: 29.7911\n",
            "Epoch 126/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.4725 - mean_absolute_error: 29.4725\n",
            "Epoch 127/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.5914 - mean_absolute_error: 29.5914\n",
            "Epoch 128/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.4595 - mean_absolute_error: 29.4595\n",
            "Epoch 129/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.6136 - mean_absolute_error: 29.6136\n",
            "Epoch 130/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.1862 - mean_absolute_error: 29.1862\n",
            "Epoch 131/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.3150 - mean_absolute_error: 29.3150\n",
            "Epoch 132/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.6224 - mean_absolute_error: 29.6224\n",
            "Epoch 133/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.3283 - mean_absolute_error: 29.3283\n",
            "Epoch 134/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.2562 - mean_absolute_error: 29.2562\n",
            "Epoch 135/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.2971 - mean_absolute_error: 29.2971\n",
            "Epoch 136/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.5266 - mean_absolute_error: 29.5266\n",
            "Epoch 137/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.1028 - mean_absolute_error: 29.1028\n",
            "Epoch 138/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.2456 - mean_absolute_error: 29.2456\n",
            "Epoch 139/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 29.1850 - mean_absolute_error: 29.1850\n",
            "Epoch 140/140\n",
            "520/520 [==============================] - 1s 2ms/step - loss: 28.8973 - mean_absolute_error: 28.8973\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f000fc0c890>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}